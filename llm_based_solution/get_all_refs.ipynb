{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from refer import REFER\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from random import randint\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset refcoco into memory...\n",
      "creating index...\n",
      "index created.\n",
      "DONE (t=5.86s)\n",
      "loading dataset refcoco+ into memory...\n",
      "creating index...\n",
      "index created.\n",
      "DONE (t=6.25s)\n",
      "loading dataset refcocog into memory...\n",
      "creating index...\n",
      "index created.\n",
      "DONE (t=5.13s)\n"
     ]
    }
   ],
   "source": [
    "data_root = './data'  # contains refclef, refcoco, refcoco+, refcocog and images\n",
    "dataset = 'refcoco'\n",
    "splitBy = 'unc'\n",
    "refer = REFER(data_root, dataset, splitBy)\n",
    "\n",
    "dataset = 'refcoco+'\n",
    "splitBy = 'unc'\n",
    "refer_plus = REFER(data_root, dataset, splitBy)\n",
    "\n",
    "dataset = 'refcocog'\n",
    "splitBy = 'google'\n",
    "refer_g = REFER(data_root, dataset, splitBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49822, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld = set(os.listdir('/media/hdd/anoskov/refcoco/MobileVLM/data/finetune_data/coco/train2014'))\n",
    "\n",
    "ref_ids = refer_g.getRefIds()\n",
    "cnt = 0\n",
    "fails = 0\n",
    "for ref_id in ref_ids:\n",
    "    img_name = refer.Refs[ref_id]['file_name'][:27] + '.jpg'\n",
    "    if img_name in ld:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        fails += 1\n",
    "cnt, fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_coords(coords):\n",
    "    x1 = coords[0] \n",
    "    x2 = coords[0] + coords[2]\n",
    "    y1 = coords[1] \n",
    "    y2 = coords[1] + coords[3]\n",
    "    return x1, x2, y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "ref_ids_train = refer.getRefIds(split='train')\n",
    "ref_ids_val = refer.getRefIds(split='val')\n",
    "ref_ids = ref_ids_train + ref_ids_val\n",
    "\n",
    "# plus\n",
    "ref_ids_train = refer_plus.getRefIds(split='train')\n",
    "ref_ids_val = refer_plus.getRefIds(split='val')\n",
    "ref_ids_plus = ref_ids_train + ref_ids_val\n",
    "\n",
    "# google\n",
    "ref_ids_train = refer_g.getRefIds(split='train')\n",
    "ref_ids_g = ref_ids_train + ref_ids_val\n",
    "\n",
    "ref_ids = [ref_ids, ref_ids_plus, ref_ids_g]\n",
    "refers = [refer, refer_plus, refer_g]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_annotations:  131458\n",
      "total_annotations:  262407\n",
      "total_annotations:  355142\n"
     ]
    }
   ],
   "source": [
    "total_annotations = 0\n",
    "\n",
    "for i, refs in enumerate(ref_ids):\n",
    "    for j, ref_id in enumerate(refs):\n",
    "        total_annotations += len(refers[i].Refs[ref_id]['sentences'])\n",
    "    print(\"total_annotations: \", total_annotations)\n",
    "new_dict = [dict() for x in range(total_annotations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_phrase = ['<image>\\nDetect ', ' and say its coordinates.']\n",
    "\n",
    "cur_idx = 0\n",
    "\n",
    "for j, refs in enumerate(ref_ids):\n",
    "    for i, ref_id in enumerate(refs):\n",
    "        ref = refers[j].Refs[ref_id]\n",
    "        replics = ref['sentences'] #['sent']\n",
    "        id = str(ref['file_name'][15:27])\n",
    "        filename = 'coco/train2014/' + ref['file_name'][:27] + '.jpg'\n",
    "        filename_for_open = '/media/hdd/anoskov/refcoco/MobileVLM/data/finetune_data/coco/train2014/' + ref['file_name'][:27] + '.jpg'\n",
    "        im_size = Image.open(filename_for_open).size\n",
    "        x, y, w, h = refer.getRefBox(ref_id)\n",
    "        x1, x2, y1, y2 = cvt_coords([x, y, w, h])\n",
    "        x1 = int(x1 / im_size[0] * 100)\n",
    "        x2 = int(x2 / im_size[0] * 100)\n",
    "        y1 = int(y1 / im_size[1] * 100)\n",
    "        y2 = int(y2 / im_size[1] * 100)\n",
    "        if (x1 < 0) or (x2 < 0) or (y1 < 0) or (y2 < 0):\n",
    "            print(x, y, w, h)\n",
    "            print(x1, x2, y1, y2)\n",
    "            print(im_size)\n",
    "            print(ref_id)\n",
    "            break\n",
    "        # conversations = [dict() for i in range(2)]\n",
    "        for it in replics:\n",
    "            item = it['sent']\n",
    "            # basic_phrase = basic_prases #basic_prases[(i + j) % len(basic_prases)]\n",
    "            phrase = basic_phrase[0] + item + basic_phrase[1]\n",
    "            conversations = [{'from': 'human', 'value': phrase},\n",
    "                {'from': 'gpt', 'value': f'Coordinates are {x1}, {x2}, {y1}, {y2}.'}]\n",
    "            new_dict[cur_idx] = {'id': id, 'image': filename, 'conversations': conversations}\n",
    "            cur_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355142"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '000000397315',\n",
       " 'image': 'coco/train2014/COCO_train2014_000000397315.jpg',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nDetect the book above margaret atwood and say its coordinates.'},\n",
       "  {'from': 'gpt', 'value': 'Coordinates are 0, 56, 0, 110.'}]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict[170000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"refcocogp_in_llava_format_train_val.json\", \"w\") as outfile:\n",
    "    json.dump(new_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "ref_ids_test = refer.getRefIds(split='test')\n",
    "\n",
    "# plus\n",
    "ref_ids_test_plus = refer_plus.getRefIds(split='test')\n",
    "\n",
    "# google\n",
    "ref_ids_test_g = refer_g.getRefIds(split='val')\n",
    "\n",
    "ref_ids = [ref_ids_test, ref_ids_test_plus, ref_ids_test_g]\n",
    "refers = [refer, refer_plus, refer_g]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_annotations:  10752\n",
      "total_annotations:  21367\n",
      "total_annotations:  30903\n"
     ]
    }
   ],
   "source": [
    "total_annotations = 0\n",
    "\n",
    "for i, refs in enumerate(ref_ids):\n",
    "    for j, ref_id in enumerate(refs):\n",
    "        total_annotations += len(refers[i].Refs[ref_id]['sentences'])\n",
    "    print(\"total_annotations: \", total_annotations)\n",
    "new_dict = [dict() for x in range(total_annotations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_phrase = ['<image>\\nDetect ', ' and say its coordinates.']\n",
    "                # ['<image>\\nFind ', ' on the image.'],\n",
    "                # ['<image>\\nGive me coordinates of the ', '.'], \n",
    "                # ['<image>\\nFind ', ' and give its coordinates.'],\n",
    "                # ['<image>\\nChoose bounding box of ', ' on the image.']]\n",
    "\n",
    "cur_idx = 0\n",
    "\n",
    "for j, refs in enumerate(ref_ids):\n",
    "    for i, ref_id in enumerate(refs):\n",
    "        ref = refers[j].Refs[ref_id]\n",
    "        replics = ref['sentences'] #['sent']\n",
    "        id = str(ref['file_name'][15:27])\n",
    "        filename = 'coco/train2014/' + ref['file_name'][:27] + '.jpg'\n",
    "        filename_for_open = '/media/hdd/anoskov/refcoco/MobileVLM/data/finetune_data/coco/train2014/' + ref['file_name'][:27] + '.jpg'\n",
    "        im_size = Image.open(filename_for_open).size\n",
    "        x, y, w, h = refer.getRefBox(ref_id)\n",
    "        x1, x2, y1, y2 = cvt_coords([x, y, w, h])\n",
    "        x1 = int(x1 / im_size[0] * 100)\n",
    "        x2 = int(x2 / im_size[0] * 100)\n",
    "        y1 = int(y1 / im_size[1] * 100)\n",
    "        y2 = int(y2 / im_size[1] * 100)\n",
    "        if (x1 < 0) or (x2 < 0) or (y1 < 0) or (y2 < 0):\n",
    "            print(x, y, w, h)\n",
    "            print(x1, x2, y1, y2)\n",
    "            print(im_size)\n",
    "            print(ref_id)\n",
    "            break\n",
    "        # conversations = [dict() for i in range(2)]\n",
    "        for it in replics:\n",
    "            item = it['sent']\n",
    "            # basic_phrase = basic_prases #basic_prases[(i + j) % len(basic_prases)]\n",
    "            phrase = basic_phrase[0] + item + basic_phrase[1]\n",
    "            conversations = [{'from': 'human', 'value': phrase},\n",
    "                {'from': 'gpt', 'value': f'Coordinates are {x1}, {x2}, {y1}, {y2}.'}]\n",
    "            new_dict[cur_idx] = {'id': id, 'image': filename, 'conversations': conversations}\n",
    "            cur_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"refcocogp_in_llava_format_test.json\", \"w\") as outfile:\n",
    "    json.dump(new_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobilevlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
